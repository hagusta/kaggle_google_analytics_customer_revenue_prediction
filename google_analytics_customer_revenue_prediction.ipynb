{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle, time, math\n",
    "from datetime import datetime\n",
    "import os \n",
    "import csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "to_drop=['visitStartTime','visitNumber','visitId','totals_hits','totals_pageviews','sessionId','fullVisitorId,'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\h_agu\\Desktop\\machine_learning\\Miniconda3\\envs\\tensorflow-gpu3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#data=pd.read_csv('train_data.csv',index_col='index')\n",
    "data=pd.read_csv('train_data.csv')\n",
    "if 'totals_transactionRevenue' in data.columns:\n",
    "    y=data.pop('totals_transactionRevenue').to_frame()\n",
    "x=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.drop(['visitStartTime','visitNumber','visitId','totals_hits','totals_pageviews','sessionId','fullVisitorId','date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in x.columns:\n",
    "    if 'visitStartTime_' in col:\n",
    "        x[col]=x[col].astype(np.object)\n",
    "    if 'date_' in col:\n",
    "        x[col]=x[col].astype(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=x.columns.tolist()\n",
    "category_features=[]\n",
    "category_features_idx=[]\n",
    "for col in features:\n",
    "    if x[col].dtypes==np.object:\n",
    "        #print(col,np.object)\n",
    "        category_features.append(col)\n",
    "        category_features_idx.append(features.index(col))\n",
    "    if x[col].dtypes==np.bool:\n",
    "        #print(col,np.bool)\n",
    "        category_features.append(col)\n",
    "        category_features_idx.append(features.index(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier,Pool\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xtrain,xtest,ytrain,ytest=train_test_split(x, y, test_size=0.1, random_state=42, shuffle=True, stratify=y)\n",
    "_y=y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_y.loc[(_y['totals_transactionRevenue']>0),'totals_transactionRevenue']=1\n",
    "_y.loc[(_y['totals_transactionRevenue']==0),'totals_transactionRevenue']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=x.columns.tolist()\n",
    "category_features=[]\n",
    "category_features_idx=[]\n",
    "for col in features:\n",
    "    if x[col].dtype == np.object or x[col].dtype == np.bool:\n",
    "        category_features.append(col)\n",
    "        category_features_idx.append(features.index(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, Trials, STATUS_OK, STATUS_FAIL, hp, pyll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(x, _y, test_size=0.4, random_state=42, shuffle=True, stratify=_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sF=StratifiedKFold(n_splits=5,shuffle=True)\n",
    "cv_split=[]\n",
    "for train_idx,test_idx in sF.split(xtrain,ytrain):\n",
    "    pool_train=Pool(xtrain.iloc[train_idx],ytrain.iloc[train_idx],cat_features=category_features_idx)\n",
    "    pool_test=Pool(xtrain.iloc[test_idx],ytrain.iloc[test_idx],cat_features=category_features_idx)\n",
    "    cv_split.append((pool_train,pool_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "            'depth': hp.choice('depth', [4,6]),\n",
    "            'border_count': hp.choice('border_count', [64,128]),\n",
    "            'learning_rate': hp.loguniform('learning_rate', -5, 0),\n",
    "            'random_strength': hp.choice('random_strength', [1,  20]),\n",
    "            'one_hot_max_size': hp.choice('one_hot_max_size', [5, 25, 225]),\n",
    "            'l2_leaf_reg': hp.loguniform('l2_leaf_reg', 0, np.log(10)),\n",
    "            'bagging_temperature': hp.uniform('bagging_temperature', 0, 1),\n",
    "            'leaf_estimation_iterations':hp.choice('leaf_estimation_iterations',[1,3,5,7,10]),\n",
    "            'max_ctr_complexity':hp.quniform('max_ctr_complexity',1,5,1),\n",
    "            'leaf_estimation_method':hp.choice('leaf_estimation_method',['Newton','Gradient']),\n",
    "            #'class_weights': (hp.choice('non_class_weights_ratio',[1]), hp.uniform('class_weights_ratio',1,20))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(params=None, dtrain=None, dtest=None, n_estimators=None, seed=0, run_time=None, run_cv_id=0, eval_no=0, verbose=False):\n",
    "    global metric,column_names\n",
    "    #print(run_cv_id, eval_no)\n",
    "    path=\"./cv_run/\"+str(run_time)\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "    fpath=path+\"/\"+str(eval_no)+\".\"+str(run_cv_id)\n",
    "    if not os.path.isdir(fpath):\n",
    "        os.mkdir(fpath)    \n",
    "    params.update({\"iterations\": n_estimators})\n",
    "    params.update({\"eval_metric\": metric})\n",
    "    params.update({\"logging_level\": 'Verbose'})\n",
    "    params.update({\"metric_period\": 100})\n",
    "    params.update({\"random_seed\": seed})\n",
    "    #params.update({\"leaf_estimation_method\": \"Newton\"})\n",
    "    #params.update({\"leaf_estimation_iterations\" : 10})\n",
    "    params.update({\"rsm\" : 1})\n",
    "    params.update({\"thread_count\" : 8})\n",
    "    params.update({\"fold_len_multiplier\": 2})\n",
    "    #params.update({\"max_ctr_complexity\":5})\n",
    "    params.update({\"train_dir\": fpath})\n",
    "    params.update({\"calc_feature_importance\" : True})\n",
    "    params.update({'od_type':'Iter'})\n",
    "    params.update({'od_wait':30})\n",
    "    \n",
    "    bst = CatBoostClassifier(**params)\n",
    "    bst.fit(dtrain, eval_set=dtest, use_best_model=True)\n",
    "    with open(fpath + \"/test_error.tsv\", \"r\") as f:\n",
    "        reader=np.array(list(csv.reader(f,delimiter='\\t'))).squeeze()\n",
    "    header=reader[0]\n",
    "    feature=dict()\n",
    "    for col, val in zip(features,bst.__dict__['_feature_importance']):\n",
    "        feature.update({col:val})\n",
    "    #pd.to_pickle(bst.__dict__['_feature_importance'],path+\"/feature_importance.\"+str(eval_no)+\".\"+str(run_cv_id))\n",
    "    pd.to_pickle(feature,path+\"/feature_importance.\"+str(eval_no)+\".\"+str(run_cv_id))\n",
    "    idx=(header==metric).argmax()\n",
    "    #print('idx',idx, metric)\n",
    "    results=(reader[1:reader.shape[0],idx]).astype(np.float)\n",
    "    \n",
    "    if metric=='AUC' or metric=='Accuracy':\n",
    "        #print(\"metric\",metric)\n",
    "        results=1-results\n",
    "    #print('results',results)\n",
    "    return bst, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_each_iter(results):\n",
    "    #global metric\n",
    "    lengs=[]\n",
    "    _=[lengs.append(len(res)) for res in results]\n",
    "    #if metric in ['AUC','Accuracy']:\n",
    "    mlen=np.max(lengs)\n",
    "    #else:\n",
    "    #    mlen=np.min(lengs)\n",
    "    #print(lengs,mlen)\n",
    "    a=[]\n",
    "    for run in results:\n",
    "        a.append((np.pad(run,(0,mlen-len(run)),'constant')).tolist())\n",
    "    x=np.array(a)\n",
    "    #print(x.shape)\n",
    "    means=[]\n",
    "    for i in range(x.shape[1]):\n",
    "        mean=0\n",
    "        count=0\n",
    "        for j in range(x.shape[0]):\n",
    "            if x[j,i] > 0:\n",
    "                count=count+1\n",
    "                mean=mean+x[j,i]\n",
    "        means.append(mean/count)\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv(cv_pairs, params=None, n_est=None, verbose=False, run_time=None):\n",
    "    global default_params,n_estimators,best_loss,hyperopt_eval_num,metric,hyperopt_evals,metric\n",
    "    params = params or default_params\n",
    "    n_estimators = n_est or n_estimators\n",
    "    #print('run_cv',hyperopt_eval_num)\n",
    "    evals_results, start_time = [], time.time()\n",
    "    _loss=[]\n",
    "    i=0\n",
    "    for dtrain, dtest in cv_pairs:\n",
    "        _, evals_result = fit(params, dtrain, dtest, n_estimators, run_time=run_time, run_cv_id=i, eval_no=hyperopt_eval_num+1)\n",
    "        #evals_results.append(np.mean(evals_result,axis=0))\n",
    "        evals_results.append(evals_result)\n",
    "        _loss.append(np.min(evals_result))\n",
    "        i=i+1\n",
    "    \n",
    "    mean_evals_results = mean_each_iter(evals_results)\n",
    "    best_n_estimators = np.argmin(mean_evals_results) + 1\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    \n",
    "    cv_result = {'loss': mean_evals_results[best_n_estimators - 1] ,\n",
    "                 'best_n_estimators': best_n_estimators, \n",
    "                 'eval_time': eval_time,\n",
    "                 'status': STATUS_FAIL if np.isnan(mean_evals_results[best_n_estimators - 1]) else STATUS_OK,\n",
    "                 'params': params.copy(),\n",
    "                 'losses': _loss\n",
    "                }\n",
    "    best_loss = min(best_loss, cv_result['loss'])\n",
    "    hyperopt_eval_num += 1\n",
    "    cv_result.update({'hyperopt_eval_num': hyperopt_eval_num, 'best_loss': best_loss})\n",
    "        \n",
    "    if verbose:\n",
    "        print ('[{0}/{1}]\\teval_time={2:.2f} sec\\tcurrent_{3}={4:.6f}\\tmin_{3}={5:.6f}'.format(\n",
    "                    hyperopt_eval_num, hyperopt_evals, eval_time,\n",
    "                    metric, cv_result['loss'], best_loss))\n",
    "    return cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "[1/20]\teval_time=533.12 sec\tcurrent_Accuracy=0.011924\tmin_Accuracy=0.011924\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "[2/20]\teval_time=116.37 sec\tcurrent_Accuracy=0.012483\tmin_Accuracy=0.011924\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "[3/20]\teval_time=331.41 sec\tcurrent_Accuracy=0.012248\tmin_Accuracy=0.011924\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "[4/20]\teval_time=143.33 sec\tcurrent_Accuracy=0.012106\tmin_Accuracy=0.011924\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "[5/20]\teval_time=355.88 sec\tcurrent_Accuracy=0.012194\tmin_Accuracy=0.011924\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "[6/20]\teval_time=50.67 sec\tcurrent_Accuracy=0.012743\tmin_Accuracy=0.011924\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "[7/20]\teval_time=64.68 sec\tcurrent_Accuracy=0.012743\tmin_Accuracy=0.011924\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "[8/20]\teval_time=251.47 sec\tcurrent_Accuracy=0.011988\tmin_Accuracy=0.011924\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "[9/20]\teval_time=80.33 sec\tcurrent_Accuracy=0.012482\tmin_Accuracy=0.011924\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "[10/20]\teval_time=53.64 sec\tcurrent_Accuracy=0.012743\tmin_Accuracy=0.011924\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "[11/20]\teval_time=53.72 sec\tcurrent_Accuracy=0.012743\tmin_Accuracy=0.011924\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "[12/20]\teval_time=359.64 sec\tcurrent_Accuracy=0.012191\tmin_Accuracy=0.011924\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "[13/20]\teval_time=214.83 sec\tcurrent_Accuracy=0.012145\tmin_Accuracy=0.011924\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "[14/20]\teval_time=77.57 sec\tcurrent_Accuracy=0.012491\tmin_Accuracy=0.011924\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "[15/20]\teval_time=180.93 sec\tcurrent_Accuracy=0.012071\tmin_Accuracy=0.011924\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "[16/20]\teval_time=163.45 sec\tcurrent_Accuracy=0.011979\tmin_Accuracy=0.011924\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "[17/20]\teval_time=181.93 sec\tcurrent_Accuracy=0.012348\tmin_Accuracy=0.011924\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "[18/20]\teval_time=248.02 sec\tcurrent_Accuracy=0.012025\tmin_Accuracy=0.011924\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "[19/20]\teval_time=45.56 sec\tcurrent_Accuracy=0.012743\tmin_Accuracy=0.011924\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "metric Accuracy\n",
      "[20/20]\teval_time=167.21 sec\tcurrent_Accuracy=0.012136\tmin_Accuracy=0.011924\n"
     ]
    }
   ],
   "source": [
    "n_estimators=1000\n",
    "max_evals = 20\n",
    "hyperopt_evals=max_evals\n",
    "metric=\"Accuracy\"\n",
    "\n",
    "this_trials = Trials()\n",
    "run_time=(datetime.now()).strftime('%Y%m%d%H%M')\n",
    "hyperopt_eval_num, best_loss, split_pair_data = 0, np.inf, None\n",
    "args=param_space\n",
    "_ = fmin(fn=lambda args: run_cv(cv_split, params=args, n_est=n_estimators, verbose=True,run_time=run_time), \n",
    "         space=args, algo=tpe.suggest, max_evals=max_evals, trials=this_trials)\n",
    "\n",
    "with open('./cv_run/'+run_time+'/trails.pickle','wb') as f:\n",
    "    pickle.dump(this_trials,f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cv_run/201810041600/trails.pickle', 'rb') as f:\n",
    "    trials=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-483615f154d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'result'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrun_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%d%H%M'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategory_features_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtestP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategory_features_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrun_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/miniconda3/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, cat_features, column_description, pairs, delimiter, has_header, weight, group_id, subgroup_id, pairs_weight, baseline, feature_names, thread_count)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/miniconda3/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, data_matrix, label, cat_features, pairs, weight, group_id, subgroup_id, pairs_weight, baseline, feature_names)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._set_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metric='Accuracy'\n",
    "arg=trials.trials[3]['result']['params']\n",
    "run_time=(datetime.now()).strftime('%Y%m%d%H%M')\n",
    "trainP=Pool(xtrain,np.log1p(ytrain),cat_features=category_features_idx)\n",
    "testP=Pool(xtest,np.log1p(ytest),cat_features=category_features_idx)\n",
    "bst,res=fit(params=arg,dtrain=trainP,dtest=testP,n_estimators=2000,seed=13,run_time=run_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('./model/model.json','wb') as f:\n",
    "bst.save_model('./model/model_class.cbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadbst=bst.load_model('./model/model_class.cbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(x, y, test_size=0.4, random_state=42, shuffle=True, stratify=_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t=_y.totals_transactionRevenue.loc[ytrain.index.to_series()]\n",
    "sF=StratifiedKFold(n_splits=5,shuffle=True)\n",
    "cv_split=[]\n",
    "for train_idx,test_idx in sF.split(xtrain,y_t):\n",
    "    pool_train_log=Pool(xtrain.iloc[train_idx],np.log1p(ytrain.iloc[train_idx]),cat_features=category_features_idx)\n",
    "    pool_test_log=Pool(xtrain.iloc[test_idx],np.log1p(ytrain.iloc[test_idx]),cat_features=category_features_idx)\n",
    "    cv_split.append((pool_train_log,pool_test_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "param=dict(\n",
    "{'bagging_temperature': 0.334998678341902,\n",
    " 'border_count': 128,\n",
    " 'depth': 4,\n",
    " 'l2_leaf_reg': 7.201514933380306,\n",
    " 'leaf_estimation_iterations': 5,\n",
    " 'leaf_estimation_method': 'Gradient',\n",
    " 'learning_rate': 0.8915171912524651,\n",
    " 'max_ctr_complexity': 4.0,\n",
    " 'one_hot_max_size': 225,\n",
    " 'random_strength': 1,\n",
    " 'iterations': 2001,\n",
    " \"logging_level\": 'Verbose',\n",
    " \"metric_period\": 100,\n",
    " #'eval_metric': 'Accuracy',\n",
    " 'logging_level': 'Silent',\n",
    " 'random_seed': 0,\n",
    " 'rsm': 1,\n",
    " 'thread_count': 8,\n",
    " 'fold_len_multiplier': 2,\n",
    " 'calc_feature_importance': True,\n",
    " 'od_type': 'Iter',\n",
    " 'od_wait': 30})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "            'depth': hp.choice('depth', [4,6,8]),\n",
    "            'border_count': hp.choice('border_count', [32,64,128]),\n",
    "            'learning_rate': hp.loguniform('learning_rate', -5, 0),\n",
    "            'random_strength': hp.choice('random_strength', [1, 5, 10, 20]),\n",
    "            'one_hot_max_size': hp.choice('one_hot_max_size', [5, 25, 225]),\n",
    "            'l2_leaf_reg': hp.loguniform('l2_leaf_reg', 0, np.log(10)),\n",
    "            'bagging_temperature': hp.uniform('bagging_temperature', 0, 1),\n",
    "            'leaf_estimation_iterations':hp.choice('leaf_estimation_iterations',[1,3,5,7,10]),\n",
    "            'max_ctr_complexity':hp.quniform('max_ctr_complexity',1,5,1),\n",
    "            'leaf_estimation_method':hp.choice('leaf_estimation_method',['Newton','Gradient']),\n",
    "            'rsm':hp.uniform('rsm',0,1),\n",
    "            'fold_len_multiplier':hp.choice('fold_len_multiplier',[1,2,3,4])\n",
    "            #'class_weights': (hp.choice('non_class_weights_ratio',[1]), hp.uniform('class_weights_ratio',1,20))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(params=None, dtrain=None, dtest=None, n_estimators=None, seed=0, run_time=None, run_cv_id=0, eval_no=0, verbose=False):\n",
    "    global metric,column_names\n",
    "    #print(run_cv_id, eval_no)\n",
    "    path=\"./cv_run/\"+str(run_time)\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "    fpath=path+\"/\"+str(eval_no)+\".\"+str(run_cv_id)\n",
    "    if not os.path.isdir(fpath):\n",
    "        os.mkdir(fpath)    \n",
    "    params.update({\"iterations\": n_estimators})\n",
    "    params.update({\"eval_metric\": metric})\n",
    "    params.update({\"logging_level\": 'Silent'})\n",
    "    params.update({\"metric_period\": 100})\n",
    "    params.update({\"random_seed\": seed})\n",
    "    #params.update({\"rsm\" : 1})\n",
    "    params.update({\"thread_count\" : 8})\n",
    "    #params.update({\"fold_len_multiplier\": 2})\n",
    "    params.update({\"train_dir\": fpath})\n",
    "    params.update({\"calc_feature_importance\" : True})\n",
    "    params.update({'od_type':'Iter'})\n",
    "    params.update({'od_wait':30})\n",
    "    bst = CatBoostRegressor(**params)\n",
    "    bst.fit(dtrain, eval_set=dtest, use_best_model=True)\n",
    "    with open(fpath + \"/test_error.tsv\", \"r\") as f:\n",
    "        reader=np.array(list(csv.reader(f,delimiter='\\t'))).squeeze()\n",
    "    header=reader[0]\n",
    "    feature=dict()\n",
    "    for col, val in zip(features,bst.__dict__['_feature_importance']):\n",
    "        feature.update({col:val})\n",
    "    #pd.to_pickle(bst.__dict__['_feature_importance'],path+\"/feature_importance.\"+str(eval_no)+\".\"+str(run_cv_id))\n",
    "    pd.to_pickle(feature,path+\"/feature_importance.\"+str(eval_no)+\".\"+str(run_cv_id))\n",
    "    idx=(header==metric).argmax()\n",
    "    #print('idx',idx, metric)\n",
    "    results=(reader[1:reader.shape[0],idx]).astype(np.float)\n",
    "    \n",
    "    if metric=='AUC' or metric=='Accuracy':\n",
    "        #print(\"metric\",metric)\n",
    "        results=1-results\n",
    "    #print('results',results)\n",
    "    return bst, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2]\teval_time=18.84 sec\tcurrent_RMSE=1.812583\tmin_RMSE=1.812583\n",
      "[2/2]\teval_time=27.98 sec\tcurrent_RMSE=1.726956\tmin_RMSE=1.726956\n"
     ]
    }
   ],
   "source": [
    "n_estimators=10\n",
    "max_evals = 2\n",
    "hyperopt_evals=max_evals\n",
    "metric=\"RMSE\"\n",
    "\n",
    "this_trials = Trials()\n",
    "run_time=(datetime.now()).strftime('%Y%m%d%H%M')\n",
    "hyperopt_eval_num, best_loss, split_pair_data = 0, np.inf, None\n",
    "args=param_space\n",
    "_ = fmin(fn=lambda args: run_cv(cv_split, params=args, n_est=n_estimators, verbose=True,run_time=run_time), \n",
    "         space=args, algo=tpe.suggest, max_evals=max_evals, trials=this_trials)\n",
    "\n",
    "with open('./cv_run/'+run_time+'/trails.pickle','wb') as f:\n",
    "    pickle.dump(this_trials,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainP=Pool(xtrain,np.log1p(ytrain),cat_features=category_features_idx)\n",
    "testP=Pool(xtest,np.log1p(ytest),cat_features=category_features_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu3",
   "language": "python",
   "name": "tensorflow-gpu3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
